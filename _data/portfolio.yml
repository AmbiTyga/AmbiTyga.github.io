- title: MemSem

  code: https://github.com/AmbiTyga/MemSem
  description: MemSem is a multi-modal framework for sentimental analysis of memes. With the help of multi modal architecture it extract features from the input to provide a meaningful analysis for a meme, whether its offensive, humorous or non-sense. The project is published in IEEE BigMM 2020 Publications and is still in progress.
  img: memsem
  used:
    - thing: Tensorflow
    - thing: Hugging Face transformer
    - thing: Python Reddit API Wrapper
    - thing: google-images-downloader
    - thing: NLTK
    - thing: Pytessaract

- title: QuesBELM

  code: https://github.com/AmbiTyga/QuesBELM
  description: QuesBELM is a natural question answering system, based on natural language processing and ensemble methods. It works on an ensemble model of BERT-base, Albert-xxl and BERT-large. Trained on SQuad2.0 dataset, preprocessed and sampled to provide better results. It produces outstanding results and is helpful for researches related to natural question answering.
  img: belm
  used:
    - thing: Pytorch
    - thing: Hugging Face transformer

# - title: Weather Widget
#   demo: http://quiet-dusk-89245.herokuapp.com/
#   code: https://github.com/bchiang7/DemoWebApp
#   description: A simple weather app I made at HubSpot's Fall 2016 Web App Workshop utilizing Node.js, Express, and Heroku. I used the OpenWeatherMap API to get weather and forecast data, and then used the current city's coordinates to create a map background that reflected the current city using the Google Maps API.
#   img: weather
#   used:
#     - thing: OpenWeatherMap API
#     - thing: Google Maps API
#     - thing: JavaScript
#     - thing: jQuery
#     - thing: CSS
#     - thing: Node.js
#     - thing: Express
#     - thing: Heroku

- title: ASL-Classifier
  code: https://github.com/AmbiTyga/ASL-Classifier
  description: ASL-Classifier is a python wrapper object. It's a real-time based classifier, helps in detecting and classifying American Sign language. With the help of Haarscascade and opencv it detects palm in the view and uses pretrained keras model in classification. It uses opencv library to create window applications to manage settings and classify output. 
  img: deafdance
  used:
  - thing: Keras
  - thing: OpenCV
  - thing: Haarscascade

# - title: Online Resume

#   code: https://github.com/bchiang7/react-profile/
#   description: This is just an online version of my resume. I forked it from . I was interested in learning React.js, so I found this <a href="https://medium.com/learning-new-stuff/building-your-first-react-js-app-d53b0c98dc#.1439cdewq">simple tutorial</a> and it kind of spun into this weekend project. I probably didn't need to use React at all, but hey, at least I learned a few things!
#   img: resume
#   used:
#   - thing: JavaScript
#   - thing: React.js
#   - thing: CSS

# - title: Old Personal Website

#   code: https://github.com/bchiang7/website_2015/
#   description: This was my first portfolio website I built in 2014. It's a simple one-pager like this one, but relied heavily on Bootstrap. Since then, I think my web development and design skills have expanded immensely.
#   img: websitev1
#   used:
#   - thing: HTML
#   - thing: CSS
#   - thing: Bootstrap
#   - thing: JavaScript
#   - thing: jQuery

- title: hiLyted

  code: https://github.com/AmbiTyga/hiLyted
  description: hiLyted is a project which clips highlights of video. It is based on the method of short time energy in audios extracted from a video. It captures the time period containing high pitch sound considering it as audience applause during the tournament. It downloads the video and audio from youtube using youtube-dl and extracts audio feature using Librosa, with the help of MoviePy it clips the time period of the highlights and saves it in a local directory.
  img: hiLyted
  used:
    - thing: Youtube-dl
    - thing: Librosa
    - thing: MoviePy
    - thing: Python

- title: Automated-Medical-Assistance

  code: https://github.com/AmbiTyga/Automated-Medical-Assistance
  description: Automated Medical Assistance is my research, where we developed a conversational dialogue system that is able to provide better medication during the need of such and is able to answer any queries related to oneâ€™s health. 
  img: AMS
  used:
    - thing: BERT,GPT2,BART
    - thing: Hugging Face-Transformers
    - thing: Pytorch
- title: Analysis of Resource-efficient Predictive Models for Natural Language Processing

  description: In this paper, we presented an analyses of the resource efficient predictive models, present in the machine learning field for resource constraint devices. These models try to minimize resource requirements like RAM and storage without hurting the accuracy much. We utilized these models on multiple benchmark natural language processing tasks, which were sentimental analysis, spam message detection, emotion analysis and fake news classification.
  img: RNLP
  used:
    - thing: Binary Neighbor Compression
    - thing: Random Forest
    - thing: SVM
    - thing: Naive Bayes
    - thing: ProtoNN
    - thing: Bonsai Tree

- title: Character Level Pretrained Language Model for Extracting Support Phrases for Sentiment Labels

  description: A novel character-level pretrained language model framework which utilizes the transformers and character-level language models to extract sentiment phrases. 
  img: clplm
  used:
    - thing: Hugging Face-Transformers
    - thing: Char-level Transformers
    - thing: RNN
    - thing: CNN
    - thing: WaveNet